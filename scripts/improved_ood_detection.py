#!/usr/bin/env python3
"""
æ”¹è¿›çš„OODæ£€æµ‹è„šæœ¬
å®æ–½å¤šç§ç­–ç•¥æå‡OODæ£€æµ‹æ€§èƒ½ï¼š
1. å¤šç§OODæ£€æµ‹æ–¹æ³• (MSP, ODIN, Mahalanobis, Energy)
2. é˜ˆå€¼ä¼˜åŒ–
3. ç‰¹å¾åˆ†æå’Œå¯è§†åŒ–
4. é›†æˆæ–¹æ³•
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import json
from pathlib import Path
import cv2
from tqdm import tqdm
import seaborn as sns
from collections import defaultdict
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.covariance import EmpiricalCovariance
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# OpenOOD imports
from openood.networks import ResNet18_224x224

class SeedOODClassifier(torch.nn.Module):
    """ç§å­OODåˆ†ç±»å™¨"""
    
    def __init__(self, num_classes):
        super(SeedOODClassifier, self).__init__()
        self.backbone = ResNet18_224x224(num_classes=num_classes)
        
    def forward(self, x):
        return self.backbone(x)
    
    def get_features(self, x):
        """è·å–ç‰¹å¾è¡¨ç¤º"""
        # è·å–å€’æ•°ç¬¬äºŒå±‚çš„ç‰¹å¾ (åœ¨å…¨è¿æ¥å±‚ä¹‹å‰)
        # å¯¹äºResNet18ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æå–ç‰¹å¾
        x = self.backbone.conv1(x)
        x = self.backbone.bn1(x)
        x = self.backbone.relu(x)
        x = self.backbone.maxpool(x)
        
        x = self.backbone.layer1(x)
        x = self.backbone.layer2(x)
        x = self.backbone.layer3(x)
        x = self.backbone.layer4(x)
        
        x = self.backbone.avgpool(x)
        features = torch.flatten(x, 1)
        return features

class ImprovedOODDetector:
    """æ”¹è¿›çš„OODæ£€æµ‹å™¨"""
    
    def __init__(self, model, device, class_to_idx):
        self.model = model
        self.device = device
        self.class_to_idx = class_to_idx
        self.num_classes = len(class_to_idx)
        
        # å­˜å‚¨è®­ç»ƒæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
        self.class_means = None
        self.class_covariances = None
        self.global_mean = None
        self.global_covariance = None
        
    def extract_features_and_logits(self, dataloader):
        """æå–ç‰¹å¾å’Œlogitsç”¨äºç»Ÿè®¡åˆ†æ"""
        self.model.eval()
        
        all_features = []
        all_logits = []
        all_labels = []
        
        with torch.no_grad():
            for images, labels, _ in tqdm(dataloader, desc="æå–ç‰¹å¾"):
                images = images.to(self.device)
                
                # è·å–ç‰¹å¾å’Œlogits
                features = self.model.get_features(images)
                logits = self.model(images)
                
                all_features.append(features.cpu().numpy())
                all_logits.append(logits.cpu().numpy())
                all_labels.append(labels.numpy())
        
        features = np.concatenate(all_features, axis=0)
        logits = np.concatenate(all_logits, axis=0)
        labels = np.concatenate(all_labels, axis=0)
        
        return features, logits, labels
    
    def fit_statistics(self, features, labels):
        """æ‹Ÿåˆè®­ç»ƒæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ”§ è®¡ç®—è®­ç»ƒæ•°æ®ç»Ÿè®¡ä¿¡æ¯...")
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡å€¼å’Œåæ–¹å·®
        self.class_means = {}
        self.class_covariances = {}
        
        for class_idx in range(self.num_classes):
            class_features = features[labels == class_idx]
            if len(class_features) > 0:
                self.class_means[class_idx] = np.mean(class_features, axis=0)
                
                # ä½¿ç”¨ç»éªŒåæ–¹å·®ä¼°è®¡
                if len(class_features) > 1:
                    cov_estimator = EmpiricalCovariance()
                    cov_estimator.fit(class_features)
                    self.class_covariances[class_idx] = cov_estimator.covariance_
                else:
                    # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œä½¿ç”¨å•ä½çŸ©é˜µ
                    self.class_covariances[class_idx] = np.eye(class_features.shape[1])
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯
        self.global_mean = np.mean(features, axis=0)
        cov_estimator = EmpiricalCovariance()
        cov_estimator.fit(features)
        self.global_covariance = cov_estimator.covariance_
        
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯è®¡ç®—å®Œæˆï¼Œç‰¹å¾ç»´åº¦: {features.shape[1]}")
    
    def msp_score(self, logits):
        """Maximum Softmax Probability (MSP) æ–¹æ³•"""
        probabilities = F.softmax(torch.tensor(logits), dim=1)
        confidence = torch.max(probabilities, dim=1)[0]
        return confidence.numpy()
    
    def odin_score(self, image, temperature=1000, epsilon=0.0014):
        """ODINæ–¹æ³• - ä½¿ç”¨æ¸©åº¦ç¼©æ”¾å’Œè¾“å…¥é¢„å¤„ç†"""
        self.model.eval()
        
        # å¯ç”¨æ¢¯åº¦è®¡ç®—
        image.requires_grad_(True)
        
        # å‰å‘ä¼ æ’­
        logits = self.model(image)
        
        # æ¸©åº¦ç¼©æ”¾
        scaled_logits = logits / temperature
        
        # è®¡ç®—æœ€å¤§ç±»åˆ«çš„æŸå¤±
        max_class = torch.argmax(scaled_logits, dim=1)
        loss = F.cross_entropy(scaled_logits, max_class)
        
        # åå‘ä¼ æ’­è·å–æ¢¯åº¦
        loss.backward()
        
        # è¾“å…¥é¢„å¤„ç† - æ·»åŠ å¯¹æŠ—æ€§å™ªå£°
        gradient = torch.sign(image.grad.data)
        perturbed_image = image - epsilon * gradient
        
        # é‡æ–°è®¡ç®—logits
        with torch.no_grad():
            perturbed_logits = self.model(perturbed_image)
            scaled_logits = perturbed_logits / temperature
            probabilities = F.softmax(scaled_logits, dim=1)
            confidence = torch.max(probabilities, dim=1)[0]
        
        return confidence.cpu().numpy()
    
    def mahalanobis_score(self, features):
        """Mahalanobisè·ç¦»æ–¹æ³•"""
        if self.class_means is None:
            raise ValueError("éœ€è¦å…ˆè°ƒç”¨fit_statisticsæ–¹æ³•")
        
        scores = []
        
        for feature in features:
            min_distance = float('inf')
            
            # è®¡ç®—åˆ°æ¯ä¸ªç±»åˆ«çš„Mahalanobisè·ç¦»
            for class_idx in range(self.num_classes):
                if class_idx in self.class_means:
                    mean = self.class_means[class_idx]
                    cov = self.class_covariances[class_idx]
                    
                    # è®¡ç®—Mahalanobisè·ç¦»
                    diff = feature - mean
                    try:
                        inv_cov = np.linalg.pinv(cov)
                        distance = np.sqrt(diff.T @ inv_cov @ diff)
                        min_distance = min(min_distance, distance)
                    except:
                        # å¦‚æœåæ–¹å·®çŸ©é˜µå¥‡å¼‚ï¼Œä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»
                        distance = np.linalg.norm(diff)
                        min_distance = min(min_distance, distance)
            
            scores.append(-min_distance)  # è´Ÿå·ä½¿å¾—æ›´é«˜çš„åˆ†æ•°è¡¨ç¤ºæ›´å¯èƒ½æ˜¯ID
        
        return np.array(scores)
    
    def energy_score(self, logits, temperature=1):
        """Energyæ–¹æ³•"""
        energy = -temperature * torch.logsumexp(torch.tensor(logits) / temperature, dim=1)
        return -energy.numpy()  # è´Ÿå·ä½¿å¾—æ›´é«˜çš„åˆ†æ•°è¡¨ç¤ºæ›´å¯èƒ½æ˜¯ID
    
    def predict_with_multiple_methods(self, image_path):
        """ä½¿ç”¨å¤šç§æ–¹æ³•é¢„æµ‹å•å¼ å›¾åƒ"""
        # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0).to(self.device)
        
        self.model.eval()
        
        with torch.no_grad():
            # è·å–logitså’Œç‰¹å¾
            logits = self.model(image_tensor)
            features = self.model.get_features(image_tensor)
            
            # åŸºæœ¬é¢„æµ‹
            probabilities = F.softmax(logits, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            
            # è®¡ç®—å„ç§OODåˆ†æ•°
            msp = self.msp_score(logits.cpu().numpy())[0]
            energy = self.energy_score(logits.cpu().numpy())[0]
            
            # Mahalanobisåˆ†æ•°
            if self.class_means is not None:
                mahalanobis = self.mahalanobis_score(features.cpu().numpy())[0]
            else:
                mahalanobis = 0.0
        
        # ODINåˆ†æ•° (éœ€è¦æ¢¯åº¦)
        image_tensor_grad = image_tensor.clone().detach().requires_grad_(True)
        try:
            odin = self.odin_score(image_tensor_grad)[0]
        except:
            odin = msp  # å¦‚æœODINå¤±è´¥ï¼Œä½¿ç”¨MSP
        
        return {
            'predicted_class': predicted_class,
            'probabilities': probabilities.cpu().numpy()[0],
            'msp_score': float(msp),
            'odin_score': float(odin),
            'mahalanobis_score': float(mahalanobis),
            'energy_score': float(energy)
        }

def load_model_and_data():
    """åŠ è½½æ¨¡å‹å’Œæ•°æ®"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åŠ è½½æ¨¡å‹é…ç½®
    with open('models/ood_evaluation_results.json', 'r', encoding='utf-8') as f:
        eval_results = json.load(f)
    
    num_classes = eval_results['num_classes']
    class_to_idx = eval_results['class_to_idx']
    
    # åŠ è½½æ¨¡å‹
    model = SeedOODClassifier(num_classes=num_classes)
    checkpoint = torch.load('models/best_seed_ood_classifier.pth', map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    
    return model, device, class_to_idx

def load_ood_images(ood_dir):
    """åŠ è½½OODæµ‹è¯•å›¾åƒ"""
    ood_dir = Path(ood_dir)
    ood_images = []
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    
    for image_path in ood_dir.rglob('*'):
        if image_path.suffix.lower() in image_extensions:
            ood_images.append({
                'path': str(image_path),
                'filename': image_path.name,
                'category': image_path.parent.name
            })
    
    return ood_images

def create_train_dataloader():
    """åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ç”¨äºç»Ÿè®¡åˆ†æ"""
    import sys
    sys.path.append('.')
    
    # ç›´æ¥å®šä¹‰æ•°æ®é›†ç±»
    class SegmentedSeedDataset(torch.utils.data.Dataset):
        def __init__(self, segmentation_info_path, transform=None):
            with open(segmentation_info_path, 'r', encoding='utf-8') as f:
                self.segmentation_info = json.load(f)
            
            self.seeds_info = self.segmentation_info['seeds_info']
            self.unique_classes = sorted(self.segmentation_info['unique_classes'])
            self.class_to_idx = {cls: idx for idx, cls in enumerate(self.unique_classes)}
            self.transform = transform
            
        def __len__(self):
            return len(self.seeds_info)
        
        def __getitem__(self, idx):
            seed_info = self.seeds_info[idx]
            image = Image.open(seed_info['path']).convert('RGB')
            image = image.resize((224, 224), Image.Resampling.LANCZOS)
            
            if self.transform:
                image = self.transform(image)
            
            seed_class = seed_info['seed_class']
            label = self.class_to_idx[seed_class]
            
            return image, label, seed_info['filename']
    
    # åˆ›å»ºå˜æ¢
    val_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = SegmentedSeedDataset(
        'datasets/seeds/segmented/segmentation_info.json', 
        transform=val_transform
    )
    
    # ä½¿ç”¨æ‰€æœ‰æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æ
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)
    
    return dataloader

def optimize_thresholds(id_scores, ood_scores, method_name):
    """ä¼˜åŒ–æ£€æµ‹é˜ˆå€¼"""
    # åˆå¹¶åˆ†æ•°å’Œæ ‡ç­¾
    all_scores = np.concatenate([id_scores, ood_scores])
    all_labels = np.concatenate([np.ones(len(id_scores)), np.zeros(len(ood_scores))])
    
    # è®¡ç®—ROCæ›²çº¿
    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)
    auc = roc_auc_score(all_labels, all_scores)
    
    # æ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼ (Youden's J statistic)
    j_scores = tpr - fpr
    optimal_idx = np.argmax(j_scores)
    optimal_threshold = thresholds[optimal_idx]
    
    return {
        'auc': auc,
        'optimal_threshold': optimal_threshold,
        'fpr': fpr,
        'tpr': tpr,
        'thresholds': thresholds
    }

def evaluate_improved_ood_detection():
    """è¯„ä¼°æ”¹è¿›çš„OODæ£€æµ‹æ–¹æ³•"""
    print("ğŸš€ å¼€å§‹æ”¹è¿›çš„OODæ£€æµ‹è¯„ä¼°")
    
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    model, device, class_to_idx = load_model_and_data()
    detector = ImprovedOODDetector(model, device, class_to_idx)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
    print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®ç»Ÿè®¡...")
    train_dataloader = create_train_dataloader()
    
    # æå–è®­ç»ƒæ•°æ®ç‰¹å¾å¹¶æ‹Ÿåˆç»Ÿè®¡ä¿¡æ¯
    train_features, train_logits, train_labels = detector.extract_features_and_logits(train_dataloader)
    detector.fit_statistics(train_features, train_labels)
    
    # åŠ è½½OODå›¾åƒ
    ood_images = load_ood_images("ç«å“ç§å­")
    print(f"ğŸ“Š æ‰¾åˆ° {len(ood_images)} ä¸ªOODå›¾åƒ")
    
    # è¯„ä¼°IDæ ·æœ¬ (ä½¿ç”¨è®­ç»ƒæ•°æ®çš„ä¸€éƒ¨åˆ†)
    print("ğŸ“Š è¯„ä¼°IDæ ·æœ¬...")
    id_results = []
    sample_indices = np.random.choice(len(train_features), min(100, len(train_features)), replace=False)
    
    for idx in tqdm(sample_indices, desc="IDæ ·æœ¬"):
        # é‡æ–°é¢„æµ‹ä»¥è·å–å®Œæ•´ç»“æœ
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰çš„ç‰¹å¾å’Œlogits
        feature = train_features[idx:idx+1]
        logit = train_logits[idx:idx+1]
        
        msp = detector.msp_score(logit)[0]
        energy = detector.energy_score(logit)[0]
        mahalanobis = detector.mahalanobis_score(feature)[0]
        
        id_results.append({
            'msp_score': msp,
            'energy_score': energy,
            'mahalanobis_score': mahalanobis,
            'odin_score': msp  # ç®€åŒ–å¤„ç†
        })
    
    # è¯„ä¼°OODæ ·æœ¬
    print("ğŸ“Š è¯„ä¼°OODæ ·æœ¬...")
    ood_results = []
    
    for ood_info in tqdm(ood_images, desc="OODæ ·æœ¬"):
        try:
            result = detector.predict_with_multiple_methods(ood_info['path'])
            result['filename'] = ood_info['filename']
            result['category'] = ood_info['category']
            ood_results.append(result)
        except Exception as e:
            print(f"âš ï¸ å¤„ç†OODå›¾åƒå¤±è´¥: {ood_info['path']}, é”™è¯¯: {e}")
    
    # åˆ†æå„ç§æ–¹æ³•çš„æ€§èƒ½
    methods = ['msp_score', 'odin_score', 'mahalanobis_score', 'energy_score']
    results = {}
    
    print("\nğŸ“Š åˆ†æå„ç§OODæ£€æµ‹æ–¹æ³•çš„æ€§èƒ½...")
    
    for method in methods:
        print(f"\nğŸ” åˆ†æ {method.upper()} æ–¹æ³•:")
        
        # æå–åˆ†æ•°
        id_scores = [r[method] for r in id_results]
        ood_scores = [r[method] for r in ood_results]
        
        # ä¼˜åŒ–é˜ˆå€¼
        method_results = optimize_thresholds(id_scores, ood_scores, method)
        
        # è®¡ç®—æ£€æµ‹æ€§èƒ½
        threshold = method_results['optimal_threshold']
        id_correct = sum(1 for score in id_scores if score >= threshold)
        ood_detected = sum(1 for score in ood_scores if score < threshold)
        
        id_accuracy = id_correct / len(id_scores) if len(id_scores) > 0 else 0
        ood_detection_rate = ood_detected / len(ood_scores) if len(ood_scores) > 0 else 0
        
        results[method] = {
            'auc': method_results['auc'],
            'optimal_threshold': threshold,
            'id_accuracy': id_accuracy,
            'ood_detection_rate': ood_detection_rate,
            'id_scores': id_scores,
            'ood_scores': ood_scores
        }
        
        print(f"  AUC: {method_results['auc']:.4f}")
        print(f"  æœ€ä¼˜é˜ˆå€¼: {threshold:.4f}")
        print(f"  IDå‡†ç¡®ç‡: {id_accuracy:.2%}")
        print(f"  OODæ£€æµ‹ç‡: {ood_detection_rate:.2%}")
    
    # å¯è§†åŒ–ç»“æœ
    plot_method_comparison(results)
    
    # é›†æˆæ–¹æ³•
    print("\nğŸ”§ å°è¯•é›†æˆæ–¹æ³•...")
    ensemble_results = evaluate_ensemble_method(results)
    
    # ä¿å­˜ç»“æœ
    save_improved_results(results, ensemble_results, ood_results)
    
    return results, ensemble_results

def plot_method_comparison(results):
    """ç»˜åˆ¶æ–¹æ³•æ¯”è¾ƒå›¾"""
    methods = list(results.keys())
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('æ”¹è¿›çš„OODæ£€æµ‹æ–¹æ³•æ¯”è¾ƒ', fontsize=16)
    
    # AUCæ¯”è¾ƒ
    aucs = [results[method]['auc'] for method in methods]
    axes[0, 0].bar(methods, aucs, color=['blue', 'red', 'green', 'orange'])
    axes[0, 0].set_title('AUCæ¯”è¾ƒ')
    axes[0, 0].set_ylabel('AUC')
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # OODæ£€æµ‹ç‡æ¯”è¾ƒ
    ood_rates = [results[method]['ood_detection_rate'] for method in methods]
    axes[0, 1].bar(methods, ood_rates, color=['blue', 'red', 'green', 'orange'])
    axes[0, 1].set_title('OODæ£€æµ‹ç‡æ¯”è¾ƒ')
    axes[0, 1].set_ylabel('æ£€æµ‹ç‡')
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒæ¯”è¾ƒ (ä»¥MSPä¸ºä¾‹)
    method = 'msp_score'
    if method in results:
        axes[1, 0].hist(results[method]['id_scores'], bins=20, alpha=0.7, label='IDæ ·æœ¬', color='blue')
        axes[1, 0].hist(results[method]['ood_scores'], bins=20, alpha=0.7, label='OODæ ·æœ¬', color='red')
        axes[1, 0].axvline(x=results[method]['optimal_threshold'], color='green', linestyle='--', label='æœ€ä¼˜é˜ˆå€¼')
        axes[1, 0].set_title(f'{method.upper()} åˆ†æ•°åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('åˆ†æ•°')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].legend()
    
    # ROCæ›²çº¿ (éœ€è¦é‡æ–°è®¡ç®—)
    for i, method in enumerate(methods):
        id_scores = results[method]['id_scores']
        ood_scores = results[method]['ood_scores']
        
        all_scores = np.concatenate([id_scores, ood_scores])
        all_labels = np.concatenate([np.ones(len(id_scores)), np.zeros(len(ood_scores))])
        
        fpr, tpr, _ = roc_curve(all_labels, all_scores)
        auc = results[method]['auc']
        
        axes[1, 1].plot(fpr, tpr, label=f'{method} (AUC={auc:.3f})')
    
    axes[1, 1].plot([0, 1], [0, 1], 'k--', alpha=0.5)
    axes[1, 1].set_title('ROCæ›²çº¿æ¯”è¾ƒ')
    axes[1, 1].set_xlabel('å‡é˜³æ€§ç‡')
    axes[1, 1].set_ylabel('çœŸé˜³æ€§ç‡')
    axes[1, 1].legend()
    
    plt.tight_layout()
    plt.savefig('models/improved_ood_comparison.png', dpi=150, bbox_inches='tight')
    print("ğŸ“Š æ–¹æ³•æ¯”è¾ƒå›¾å·²ä¿å­˜åˆ°: models/improved_ood_comparison.png")

def evaluate_ensemble_method(results):
    """è¯„ä¼°é›†æˆæ–¹æ³•"""
    methods = list(results.keys())
    
    # ç®€å•å¹³å‡é›†æˆ
    id_ensemble_scores = []
    ood_ensemble_scores = []
    
    for i in range(len(results[methods[0]]['id_scores'])):
        scores = [results[method]['id_scores'][i] for method in methods]
        id_ensemble_scores.append(np.mean(scores))
    
    for i in range(len(results[methods[0]]['ood_scores'])):
        scores = [results[method]['ood_scores'][i] for method in methods]
        ood_ensemble_scores.append(np.mean(scores))
    
    # ä¼˜åŒ–é›†æˆé˜ˆå€¼
    ensemble_results = optimize_thresholds(id_ensemble_scores, ood_ensemble_scores, 'ensemble')
    
    # è®¡ç®—æ€§èƒ½
    threshold = ensemble_results['optimal_threshold']
    id_correct = sum(1 for score in id_ensemble_scores if score >= threshold)
    ood_detected = sum(1 for score in ood_ensemble_scores if score < threshold)
    
    id_accuracy = id_correct / len(id_ensemble_scores)
    ood_detection_rate = ood_detected / len(ood_ensemble_scores)
    
    print(f"ğŸ¯ é›†æˆæ–¹æ³•ç»“æœ:")
    print(f"  AUC: {ensemble_results['auc']:.4f}")
    print(f"  æœ€ä¼˜é˜ˆå€¼: {threshold:.4f}")
    print(f"  IDå‡†ç¡®ç‡: {id_accuracy:.2%}")
    print(f"  OODæ£€æµ‹ç‡: {ood_detection_rate:.2%}")
    
    return {
        'auc': ensemble_results['auc'],
        'optimal_threshold': threshold,
        'id_accuracy': id_accuracy,
        'ood_detection_rate': ood_detection_rate,
        'id_scores': id_ensemble_scores,
        'ood_scores': ood_ensemble_scores
    }

def save_improved_results(results, ensemble_results, ood_results):
    """ä¿å­˜æ”¹è¿›çš„ç»“æœ"""
    # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨
    for method in results:
        results[method]['id_scores'] = [float(x) for x in results[method]['id_scores']]
        results[method]['ood_scores'] = [float(x) for x in results[method]['ood_scores']]
    
    ensemble_results['id_scores'] = [float(x) for x in ensemble_results['id_scores']]
    ensemble_results['ood_scores'] = [float(x) for x in ensemble_results['ood_scores']]
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = {
        'method_results': results,
        'ensemble_results': ensemble_results,
        'ood_predictions': [{
            'filename': r['filename'],
            'category': r['category'],
            'predicted_class': r['predicted_class'],
            'probabilities': r['probabilities'].tolist() if hasattr(r['probabilities'], 'tolist') else r['probabilities'],
            'msp_score': r['msp_score'],
            'odin_score': r['odin_score'],
            'mahalanobis_score': r['mahalanobis_score'],
            'energy_score': r['energy_score']
        } for r in ood_results]
    }
    
    results_path = "models/improved_ood_results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ”¹è¿›çš„OODæ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {results_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ æ”¹è¿›çš„ç§å­OODæ£€æµ‹è¯„ä¼°")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        'models/best_seed_ood_classifier.pth',
        'models/ood_evaluation_results.json',
        'datasets/seeds/segmented/segmentation_info.json'
    ]
    
    for file_path in required_files:
        if not Path(file_path).exists():
            print(f"âŒ å¿…è¦æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
    
    # è¿è¡Œæ”¹è¿›çš„è¯„ä¼°
    results, ensemble_results = evaluate_improved_ood_detection()
    
    # æ€»ç»“æœ€ä½³æ–¹æ³•
    print("\nğŸ† æ–¹æ³•æ€§èƒ½æ€»ç»“:")
    print("=" * 60)
    
    best_auc = 0
    best_method = ""
    
    for method, result in results.items():
        print(f"{method.upper():15} | AUC: {result['auc']:.4f} | OODæ£€æµ‹ç‡: {result['ood_detection_rate']:.2%}")
        if result['auc'] > best_auc:
            best_auc = result['auc']
            best_method = method
    
    print(f"{'ENSEMBLE':15} | AUC: {ensemble_results['auc']:.4f} | OODæ£€æµ‹ç‡: {ensemble_results['ood_detection_rate']:.2%}")
    
    if ensemble_results['auc'] > best_auc:
        best_method = "ENSEMBLE"
        best_auc = ensemble_results['auc']
    
    print("=" * 60)
    print(f"ğŸ¥‡ æœ€ä½³æ–¹æ³•: {best_method} (AUC: {best_auc:.4f})")
    
    print("\nğŸ‰ æ”¹è¿›çš„OODæ£€æµ‹è¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main() 