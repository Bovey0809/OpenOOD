#!/usr/bin/env python3
"""
ç§å­OODæ£€æµ‹åˆ†ç±»å™¨è®­ç»ƒè„šæœ¬
ä½¿ç”¨åˆ†å‰²åçš„ç§å­æ•°æ®å’ŒçœŸå®ç±»åˆ«æ ‡ç­¾è®­ç»ƒåˆ†ç±»æ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as transforms
from PIL import Image
import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import cv2
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from collections import defaultdict

# OpenOOD imports
from openood.networks import ResNet18_224x224

class SegmentedSeedDataset(Dataset):
    """åˆ†å‰²ç§å­æ•°æ®é›†ç±»"""
    
    def __init__(self, segmentation_info_path, transform=None, target_size=(224, 224)):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            segmentation_info_path: åˆ†å‰²ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„
            transform: æ•°æ®å˜æ¢
            target_size: ç›®æ ‡å›¾åƒå°ºå¯¸
        """
        self.target_size = target_size
        self.transform = transform
        
        # åŠ è½½åˆ†å‰²ä¿¡æ¯
        with open(segmentation_info_path, 'r', encoding='utf-8') as f:
            self.segmentation_info = json.load(f)
        
        self.seeds_info = self.segmentation_info['seeds_info']
        
        # è·å–ç±»åˆ«ä¿¡æ¯
        self.class_distribution = self.segmentation_info['class_distribution']
        self.unique_classes = sorted(self.segmentation_info['unique_classes'])
        self.num_classes = len(self.unique_classes)
        
        # åˆ›å»ºç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.unique_classes)}
        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}
        
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"  æ€»ç§å­æ•°: {len(self.seeds_info)}")
        print(f"  ç±»åˆ«æ•°: {self.num_classes}")
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {self.class_distribution}")
        print(f"  ç±»åˆ«æ˜ å°„: {self.class_to_idx}")
        
    def __len__(self):
        return len(self.seeds_info)
    
    def __getitem__(self, idx):
        seed_info = self.seeds_info[idx]
        
        # åŠ è½½ç§å­å›¾åƒ
        image_path = seed_info['path']
        image = Image.open(image_path).convert('RGB')
        
        # è°ƒæ•´å›¾åƒå¤§å°
        image = image.resize(self.target_size, Image.Resampling.LANCZOS)
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        # è·å–çœŸå®ç±»åˆ«æ ‡ç­¾
        seed_class = seed_info['seed_class']
        label = self.class_to_idx[seed_class]
        
        return image, label, seed_info['filename']

def create_data_transforms():
    """åˆ›å»ºæ•°æ®å˜æ¢"""
    
    # è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼º
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.5),
        transforms.RandomRotation(degrees=30),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # éªŒè¯/æµ‹è¯•æ—¶çš„å˜æ¢
    val_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform

def create_data_loaders(segmentation_info_path, batch_size=32, val_split=0.2):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    
    train_transform, val_transform = create_data_transforms()
    
    # åˆ›å»ºå®Œæ•´æ•°æ®é›†
    full_dataset = SegmentedSeedDataset(segmentation_info_path, transform=None)
    
    # åˆ†å‰²æ•°æ®é›†
    total_size = len(full_dataset)
    val_size = int(total_size * val_split)
    train_size = total_size - val_size
    
    train_indices, val_indices = random_split(
        range(total_size), 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    # åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
    train_dataset = SegmentedSeedDataset(segmentation_info_path, transform=train_transform)
    val_dataset = SegmentedSeedDataset(segmentation_info_path, transform=val_transform)
    
    # ä½¿ç”¨ç´¢å¼•åˆ›å»ºå­é›†
    train_subset = torch.utils.data.Subset(train_dataset, train_indices)
    val_subset = torch.utils.data.Subset(val_dataset, val_indices)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_subset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=4,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_subset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"  è®­ç»ƒé›†: {len(train_subset)} ä¸ªç§å­")
    print(f"  éªŒè¯é›†: {len(val_subset)} ä¸ªç§å­")
    
    return train_loader, val_loader, full_dataset.num_classes, full_dataset.class_to_idx

class SeedOODClassifier(nn.Module):
    """ç§å­OODåˆ†ç±»å™¨"""
    
    def __init__(self, num_classes, pretrained=False):
        super(SeedOODClassifier, self).__init__()
        
        # ä½¿ç”¨OpenOODçš„ResNet18
        self.backbone = ResNet18_224x224(num_classes=num_classes)
        
    def forward(self, x):
        return self.backbone(x)

class SeedOODTrainer:
    """ç§å­OODåˆ†ç±»å™¨è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, num_classes, class_to_idx, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.num_classes = num_classes
        self.class_to_idx = class_to_idx
        self.idx_to_class = {v: k for k, v in class_to_idx.items()}
        self.device = device
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)
        
        # è®­ç»ƒå†å²
        self.train_losses = []
        self.train_accuracies = []
        self.val_losses = []
        self.val_accuracies = []
        
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(self.train_loader, desc="Training")
        for batch_idx, (images, labels, _) in enumerate(pbar):
            images, labels = images.to(self.device), labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            # ç»Ÿè®¡
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'Loss': f'{running_loss/(batch_idx+1):.4f}',
                'Acc': f'{100.*correct/total:.2f}%'
            })
        
        epoch_loss = running_loss / len(self.train_loader)
        epoch_acc = 100. * correct / total
        
        return epoch_loss, epoch_acc
    
    def validate_epoch(self):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        running_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for images, labels, _ in tqdm(self.val_loader, desc="Validation"):
                images, labels = images.to(self.device), labels.to(self.device)
                
                outputs = self.model(images)
                loss = self.criterion(outputs, labels)
                
                running_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
        
        epoch_loss = running_loss / len(self.val_loader)
        epoch_acc = 100. * correct / total
        
        return epoch_loss, epoch_acc
    
    def train(self, num_epochs=30):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch")
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ¯ ç±»åˆ«æ•°: {self.num_classes}")
        
        best_val_acc = 0.0
        best_model_path = "models/best_seed_ood_classifier.pth"
        
        # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
        Path("models").mkdir(exist_ok=True)
        
        for epoch in range(num_epochs):
            print(f"\nğŸ“… Epoch {epoch+1}/{num_epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch()
            
            # éªŒè¯
            val_loss, val_acc = self.validate_epoch()
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            
            # è®°å½•å†å²
            self.train_losses.append(train_loss)
            self.train_accuracies.append(train_acc)
            self.val_losses.append(val_loss)
            self.val_accuracies.append(val_acc)
            
            # æ‰“å°ç»“æœ
            print(f"è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
            print(f"éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")
            print(f"å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'val_acc': val_acc,
                    'num_classes': self.num_classes,
                    'class_to_idx': self.class_to_idx
                }, best_model_path)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%)")
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
        return best_model_path
    
    def plot_training_history(self, save_path="models/training_history.png"):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # æŸå¤±æ›²çº¿
        ax1.plot(self.train_losses, label='è®­ç»ƒæŸå¤±', color='blue')
        ax1.plot(self.val_losses, label='éªŒè¯æŸå¤±', color='red')
        ax1.set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # å‡†ç¡®ç‡æ›²çº¿
        ax2.plot(self.train_accuracies, label='è®­ç»ƒå‡†ç¡®ç‡', color='blue')
        ax2.plot(self.val_accuracies, label='éªŒè¯å‡†ç¡®ç‡', color='red')
        ax2.set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ“Š è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        try:
            plt.show()
        except:
            print("âš ï¸  æ— æ³•æ˜¾ç¤ºå›¾åƒï¼Œä½†å·²ä¿å­˜åˆ°æ–‡ä»¶")

def evaluate_ood_detection(model, val_loader, device, class_to_idx):
    """è¯„ä¼°OODæ£€æµ‹æ€§èƒ½"""
    model.eval()
    
    all_predictions = []
    all_labels = []
    all_confidences = []
    all_filenames = []
    
    with torch.no_grad():
        for images, labels, filenames in tqdm(val_loader, desc="OODè¯„ä¼°"):
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            probabilities = torch.softmax(outputs, dim=1)
            confidences = torch.max(probabilities, dim=1)[0]
            predictions = torch.argmax(outputs, dim=1)
            
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_confidences.extend(confidences.cpu().numpy())
            all_filenames.extend(filenames)
    
    # è®¡ç®—åˆ†ç±»æŠ¥å‘Š
    idx_to_class = {v: k for k, v in class_to_idx.items()}
    class_names = [f"ç±»åˆ«{idx_to_class[i]}" for i in range(len(class_to_idx))]
    
    print("\nğŸ“Š åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(all_labels, all_predictions, target_names=class_names))
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_predictions)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig("models/confusion_matrix.png", dpi=150, bbox_inches='tight')
    print("ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: models/confusion_matrix.png")
    
    # ç½®ä¿¡åº¦åˆ†æ
    confidence_threshold = np.percentile(all_confidences, 5)  # ä½¿ç”¨5%åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
    
    print(f"\nğŸ¯ OODæ£€æµ‹åˆ†æ:")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {np.mean(all_confidences):.4f}")
    print(f"ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std(all_confidences):.4f}")
    print(f"å»ºè®®OODé˜ˆå€¼: {confidence_threshold:.4f}")
    
    # æŒ‰ç±»åˆ«åˆ†æç½®ä¿¡åº¦
    class_confidences = defaultdict(list)
    for pred, conf in zip(all_predictions, all_confidences):
        class_confidences[pred].append(conf)
    
    print(f"\nğŸ“ˆ å„ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ:")
    for class_idx in sorted(class_confidences.keys()):
        class_conf = class_confidences[class_idx]
        print(f"  ç±»åˆ«{idx_to_class[class_idx]}: å¹³å‡={np.mean(class_conf):.4f}, "
              f"æ ‡å‡†å·®={np.std(class_conf):.4f}, æ ·æœ¬æ•°={len(class_conf)}")
    
    return {
        'predictions': all_predictions,
        'labels': all_labels,
        'confidences': all_confidences,
        'filenames': all_filenames,
        'ood_threshold': confidence_threshold
    }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ± ç§å­OODæ£€æµ‹åˆ†ç±»å™¨è®­ç»ƒ")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"ğŸ”¥ GPUä¿¡æ¯: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # æ•°æ®è·¯å¾„
    segmentation_info_path = "datasets/seeds/segmented/segmentation_info.json"
    
    if not Path(segmentation_info_path).exists():
        print(f"âŒ åˆ†å‰²ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {segmentation_info_path}")
        print("è¯·å…ˆè¿è¡Œ python scripts/segment_seeds.py")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“Š å‡†å¤‡æ•°æ®...")
    train_loader, val_loader, num_classes, class_to_idx = create_data_loaders(
        segmentation_info_path, 
        batch_size=32, 
        val_split=0.2
    )
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºæ¨¡å‹ (ç±»åˆ«æ•°: {num_classes})...")
    model = SeedOODClassifier(num_classes=num_classes)
    model = model.to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°: æ€»è®¡={total_params:,}, å¯è®­ç»ƒ={trainable_params:,}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SeedOODTrainer(model, train_loader, val_loader, num_classes, class_to_idx, device)
    
    # è®­ç»ƒæ¨¡å‹
    best_model_path = trainer.train(num_epochs=30)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    trainer.plot_training_history()
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°
    print("\nğŸ“Š åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°...")
    checkpoint = torch.load(best_model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # è¯„ä¼°OODæ£€æµ‹æ€§èƒ½
    ood_results = evaluate_ood_detection(model, val_loader, device, class_to_idx)
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    results_path = "models/ood_evaluation_results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        json_results = {
            'ood_threshold': float(ood_results['ood_threshold']),
            'num_classes': num_classes,
            'class_to_idx': class_to_idx,
            'predictions': [int(x) for x in ood_results['predictions']],
            'labels': [int(x) for x in ood_results['labels']],
            'confidences': [float(x) for x in ood_results['confidences']],
            'filenames': ood_results['filenames']
        }
        json.dump(json_results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    print(f"ğŸ‰ è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {best_model_path}")

if __name__ == "__main__":
    main() 