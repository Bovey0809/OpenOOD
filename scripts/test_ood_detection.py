#!/usr/bin/env python3
"""
OODæ£€æµ‹æµ‹è¯•è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æµ‹è¯•ç«å“ç§å­ï¼ˆå¤–æ¥ç§å­ï¼‰çš„æ£€æµ‹èƒ½åŠ›
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import json
from pathlib import Path
import cv2
from tqdm import tqdm
import seaborn as sns
from collections import defaultdict

# OpenOOD imports
from openood.networks import ResNet18_224x224

class SeedOODClassifier(torch.nn.Module):
    """ç§å­OODåˆ†ç±»å™¨"""
    
    def __init__(self, num_classes):
        super(SeedOODClassifier, self).__init__()
        self.backbone = ResNet18_224x224(num_classes=num_classes)
        
    def forward(self, x):
        return self.backbone(x)

def load_model(model_path, num_classes, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model = SeedOODClassifier(num_classes=num_classes)
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(model_path, map_location=device)
    
    # å¦‚æœcheckpointåŒ…å«model_state_dictï¼Œåˆ™ä½¿ç”¨å®ƒï¼›å¦åˆ™ç›´æ¥ä½¿ç”¨checkpoint
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    return model

def create_test_transform():
    """åˆ›å»ºæµ‹è¯•æ•°æ®å˜æ¢"""
    return transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

def load_ood_images(ood_dir):
    """åŠ è½½OODæµ‹è¯•å›¾åƒï¼ˆç«å“ç§å­ï¼‰"""
    ood_dir = Path(ood_dir)
    ood_images = []
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    
    print(f"ğŸ” æ‰«æOODå›¾åƒç›®å½•: {ood_dir}")
    
    # é€’å½’æœç´¢æ‰€æœ‰å›¾åƒæ–‡ä»¶
    for image_path in ood_dir.rglob('*'):
        if image_path.suffix.lower() in image_extensions:
            ood_images.append({
                'path': str(image_path),
                'filename': image_path.name,
                'category': image_path.parent.name
            })
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(ood_images)} ä¸ªOODå›¾åƒ")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    category_counts = defaultdict(int)
    for img in ood_images:
        category_counts[img['category']] += 1
    
    print("ğŸ“ˆ OODå›¾åƒåˆ†å¸ƒ:")
    for category, count in category_counts.items():
        print(f"  {category}: {count} å¼ ")
    
    return ood_images

def predict_with_confidence(model, image, transform, device):
    """é¢„æµ‹å›¾åƒå¹¶è¿”å›ç½®ä¿¡åº¦"""
    # é¢„å¤„ç†å›¾åƒ
    if isinstance(image, str):
        image = Image.open(image).convert('RGB')
    
    image_tensor = transform(image).unsqueeze(0).to(device)
    
    with torch.no_grad():
        logits = model(image_tensor)
        probabilities = F.softmax(logits, dim=1)
        confidence = torch.max(probabilities, dim=1)[0].item()
        predicted_class = torch.argmax(probabilities, dim=1).item()
    
    return predicted_class, confidence, probabilities.cpu().numpy()[0]

def evaluate_ood_detection(model, id_images, ood_images, transform, device, class_to_idx, threshold=0.3816):
    """è¯„ä¼°OODæ£€æµ‹æ€§èƒ½"""
    
    print(f"\nğŸ¯ å¼€å§‹OODæ£€æµ‹è¯„ä¼° (é˜ˆå€¼: {threshold:.4f})")
    
    # åŠ è½½IDæ•°æ®çš„åˆ†å‰²ä¿¡æ¯
    with open('datasets/seeds/segmented/segmentation_info.json', 'r', encoding='utf-8') as f:
        segmentation_info = json.load(f)
    
    id_seeds = segmentation_info['seeds_info']
    
    # è¯„ä¼°IDæ ·æœ¬
    print("ğŸ“Š è¯„ä¼°IDæ ·æœ¬...")
    id_results = []
    
    for seed_info in tqdm(id_seeds[:100], desc="IDæ ·æœ¬"):  # å–å‰100ä¸ªæ ·æœ¬æµ‹è¯•
        try:
            predicted_class, confidence, probs = predict_with_confidence(
                model, seed_info['path'], transform, device
            )
            
            id_results.append({
                'filename': seed_info['filename'],
                'true_class': seed_info['seed_class'],
                'predicted_class': predicted_class,
                'confidence': confidence,
                'is_ood_detected': confidence < threshold,
                'probabilities': probs
            })
        except Exception as e:
            print(f"âš ï¸ å¤„ç†IDå›¾åƒå¤±è´¥: {seed_info['path']}, é”™è¯¯: {e}")
    
    # è¯„ä¼°OODæ ·æœ¬
    print("ğŸ“Š è¯„ä¼°OODæ ·æœ¬...")
    ood_results = []
    
    for ood_info in tqdm(ood_images, desc="OODæ ·æœ¬"):
        try:
            predicted_class, confidence, probs = predict_with_confidence(
                model, ood_info['path'], transform, device
            )
            
            ood_results.append({
                'filename': ood_info['filename'],
                'category': ood_info['category'],
                'predicted_class': predicted_class,
                'confidence': confidence,
                'is_ood_detected': confidence < threshold,
                'probabilities': probs
            })
        except Exception as e:
            print(f"âš ï¸ å¤„ç†OODå›¾åƒå¤±è´¥: {ood_info['path']}, é”™è¯¯: {e}")
    
    return id_results, ood_results

def calculate_metrics(id_results, ood_results):
    """è®¡ç®—OODæ£€æµ‹æŒ‡æ ‡"""
    
    # IDæ ·æœ¬ä¸­è¢«é”™è¯¯æ£€æµ‹ä¸ºOODçš„æ•°é‡ï¼ˆå‡é˜³æ€§ï¼‰
    id_false_positives = sum(1 for r in id_results if r['is_ood_detected'])
    id_total = len(id_results)
    
    # OODæ ·æœ¬ä¸­è¢«æ­£ç¡®æ£€æµ‹ä¸ºOODçš„æ•°é‡ï¼ˆçœŸé˜³æ€§ï¼‰
    ood_true_positives = sum(1 for r in ood_results if r['is_ood_detected'])
    ood_total = len(ood_results)
    
    # è®¡ç®—æŒ‡æ ‡
    id_accuracy = (id_total - id_false_positives) / id_total if id_total > 0 else 0
    ood_detection_rate = ood_true_positives / ood_total if ood_total > 0 else 0
    
    # æ•´ä½“å‡†ç¡®ç‡
    total_correct = (id_total - id_false_positives) + ood_true_positives
    total_samples = id_total + ood_total
    overall_accuracy = total_correct / total_samples if total_samples > 0 else 0
    
    return {
        'id_accuracy': id_accuracy,
        'ood_detection_rate': ood_detection_rate,
        'overall_accuracy': overall_accuracy,
        'id_false_positives': id_false_positives,
        'id_total': id_total,
        'ood_true_positives': ood_true_positives,
        'ood_total': ood_total
    }

def plot_confidence_distribution(id_results, ood_results, threshold, save_path="models/confidence_distribution.png"):
    """ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒå›¾"""
    
    id_confidences = [r['confidence'] for r in id_results]
    ood_confidences = [r['confidence'] for r in ood_results]
    
    plt.figure(figsize=(12, 6))
    
    # ç»˜åˆ¶ç›´æ–¹å›¾
    plt.hist(id_confidences, bins=30, alpha=0.7, label=f'IDæ ·æœ¬ (n={len(id_confidences)})', color='blue')
    plt.hist(ood_confidences, bins=30, alpha=0.7, label=f'OODæ ·æœ¬ (n={len(ood_confidences)})', color='red')
    
    # æ·»åŠ é˜ˆå€¼çº¿
    plt.axvline(x=threshold, color='green', linestyle='--', linewidth=2, label=f'OODé˜ˆå€¼ ({threshold:.4f})')
    
    plt.xlabel('ç½®ä¿¡åº¦')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('ID vs OOD ç½®ä¿¡åº¦åˆ†å¸ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.show()
    
    print(f"ğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")

def analyze_ood_categories(ood_results):
    """åˆ†æä¸åŒOODç±»åˆ«çš„æ£€æµ‹æ•ˆæœ"""
    
    category_stats = defaultdict(lambda: {'total': 0, 'detected': 0, 'confidences': []})
    
    for result in ood_results:
        category = result['category']
        category_stats[category]['total'] += 1
        category_stats[category]['confidences'].append(result['confidence'])
        if result['is_ood_detected']:
            category_stats[category]['detected'] += 1
    
    print("\nğŸ“ˆ å„OODç±»åˆ«æ£€æµ‹æ•ˆæœ:")
    for category, stats in category_stats.items():
        detection_rate = stats['detected'] / stats['total'] if stats['total'] > 0 else 0
        avg_confidence = np.mean(stats['confidences'])
        print(f"  {category}: æ£€æµ‹ç‡={detection_rate:.2%}, å¹³å‡ç½®ä¿¡åº¦={avg_confidence:.4f}, æ ·æœ¬æ•°={stats['total']}")
    
    return category_stats

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ” ç§å­OODæ£€æµ‹æµ‹è¯•")
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹é…ç½®
    model_path = "models/best_seed_ood_classifier.pth"
    evaluation_results_path = "models/ood_evaluation_results.json"
    
    if not Path(model_path).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ train_ood_classifier.py è®­ç»ƒæ¨¡å‹")
        return
    
    # åŠ è½½è¯„ä¼°ç»“æœè·å–é…ç½®ä¿¡æ¯
    with open(evaluation_results_path, 'r', encoding='utf-8') as f:
        eval_results = json.load(f)
    
    num_classes = eval_results['num_classes']
    class_to_idx = eval_results['class_to_idx']
    suggested_threshold = eval_results['ood_threshold']
    
    print(f"ğŸ“Š æ¨¡å‹é…ç½®: {num_classes} ä¸ªç±»åˆ«")
    print(f"ğŸ¯ å»ºè®®OODé˜ˆå€¼: {suggested_threshold:.4f}")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ—ï¸ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    model = load_model(model_path, num_classes, device)
    
    # åˆ›å»ºæ•°æ®å˜æ¢
    transform = create_test_transform()
    
    # åŠ è½½OODå›¾åƒï¼ˆç«å“ç§å­ï¼‰
    ood_dir = "ç«å“ç§å­"
    if not Path(ood_dir).exists():
        print(f"âŒ OODæ•°æ®ç›®å½•ä¸å­˜åœ¨: {ood_dir}")
        return
    
    ood_images = load_ood_images(ood_dir)
    if len(ood_images) == 0:
        print("âŒ æœªæ‰¾åˆ°OODå›¾åƒ")
        return
    
    # è¯„ä¼°OODæ£€æµ‹
    id_results, ood_results = evaluate_ood_detection(
        model, None, ood_images, transform, device, class_to_idx, suggested_threshold
    )
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_metrics(id_results, ood_results)
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ¯ OODæ£€æµ‹ç»“æœ:")
    print(f"  IDæ ·æœ¬å‡†ç¡®ç‡: {metrics['id_accuracy']:.2%} ({metrics['id_total'] - metrics['id_false_positives']}/{metrics['id_total']})")
    print(f"  OODæ£€æµ‹ç‡: {metrics['ood_detection_rate']:.2%} ({metrics['ood_true_positives']}/{metrics['ood_total']})")
    print(f"  æ•´ä½“å‡†ç¡®ç‡: {metrics['overall_accuracy']:.2%}")
    
    # åˆ†æOODç±»åˆ«
    category_stats = analyze_ood_categories(ood_results)
    
    # ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ
    plot_confidence_distribution(id_results, ood_results, suggested_threshold)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = {
        'metrics': metrics,
        'threshold': suggested_threshold,
        'id_results': [{
            'filename': r['filename'],
            'true_class': r['true_class'],
            'predicted_class': r['predicted_class'],
            'confidence': float(r['confidence']),
            'is_ood_detected': r['is_ood_detected'],
            'probabilities': r['probabilities'].tolist() if hasattr(r['probabilities'], 'tolist') else r['probabilities']
        } for r in id_results],
        'ood_results': [{
            'filename': r['filename'],
            'category': r['category'],
            'predicted_class': r['predicted_class'],
            'confidence': float(r['confidence']),
            'is_ood_detected': r['is_ood_detected'],
            'probabilities': r['probabilities'].tolist() if hasattr(r['probabilities'], 'tolist') else r['probabilities']
        } for r in ood_results],
        'category_stats': {k: {
            'total': v['total'],
            'detected': v['detected'],
            'detection_rate': v['detected'] / v['total'] if v['total'] > 0 else 0,
            'avg_confidence': float(np.mean(v['confidences']))
        } for k, v in category_stats.items()}
    }
    
    results_path = "models/ood_test_results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    print("ğŸ‰ OODæ£€æµ‹æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main() 