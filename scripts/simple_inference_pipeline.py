#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆç§å­åˆ†ç±»å’ŒOODæ£€æµ‹æ¨ç†ç®¡é“
ç§»é™¤å¤æ‚ä¾èµ–ï¼Œä¸“æ³¨äºæ ¸å¿ƒæ¨ç†åŠŸèƒ½
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass, asdict
import time
import argparse

# OpenOOD imports
from openood.networks import ResNet18_224x224

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DetectionResult:
    """æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    filename: str
    predicted_class: str
    predicted_class_name: str
    confidence: float
    is_ood: bool
    probabilities: Dict[str, float]
    processing_time: float
    method: str = "ODIN"
    error: Optional[str] = None
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)

class SeedOODClassifier(torch.nn.Module):
    """ç§å­OODåˆ†ç±»å™¨"""
    
    def __init__(self, num_classes=10):
        super().__init__()
        self.backbone = ResNet18_224x224(num_classes=num_classes)
        self.num_classes = num_classes
        
    def forward(self, x):
        return self.backbone(x)

class SimpleInferencePipeline:
    """ç®€åŒ–ç‰ˆæ¨ç†ç®¡é“"""
    
    def __init__(self, 
                 model_path: str = "models/best_seed_ood_classifier.pth",
                 eval_results_path: str = "models/ood_evaluation_results.json",
                 device: str = "auto",
                 odin_temperature: float = 1000.0,
                 odin_epsilon: float = 0.0014,
                 ood_threshold: float = 0.2591):
        
        self.model_path = model_path
        self.eval_results_path = eval_results_path
        self.odin_temperature = odin_temperature
        self.odin_epsilon = odin_epsilon
        self.ood_threshold = ood_threshold
        
        # è®¾å¤‡è®¾ç½®
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹é…ç½®
        self._load_eval_results()
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
        
        # è®¾ç½®æ•°æ®å˜æ¢
        self._setup_transforms()
        
        logger.info("æ¨ç†ç®¡é“åˆå§‹åŒ–å®Œæˆ")
    
    def _load_eval_results(self):
        """åŠ è½½è¯„ä¼°ç»“æœ"""
        try:
            with open(self.eval_results_path, 'r', encoding='utf-8') as f:
                eval_results = json.load(f)
            
            self.num_classes = eval_results['num_classes']
            self.class_to_idx = eval_results['class_to_idx']
            self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
            
            logger.info(f"åŠ è½½æ¨¡å‹é…ç½®: {self.num_classes} ä¸ªç±»åˆ«")
            
        except Exception as e:
            logger.error(f"åŠ è½½è¯„ä¼°ç»“æœå¤±è´¥: {e}")
            raise
    
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            self.model = SeedOODClassifier(num_classes=self.num_classes)
            
            # åŠ è½½checkpoint
            checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
            if 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
            else:
                self.model.load_state_dict(checkpoint)
            
            self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ: {self.model_path}")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _setup_transforms(self):
        """è®¾ç½®æ•°æ®å˜æ¢"""
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def _odin_score(self, inputs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """è®¡ç®—ODINåˆ†æ•°"""
        inputs.requires_grad_(True)
        
        # å‰å‘ä¼ æ’­
        logits = self.model(inputs)
        
        # è®¡ç®—æœ€å¤§logitå¯¹åº”çš„æŸå¤±
        max_logits = logits.max(dim=1)[0]
        loss = max_logits.sum()
        
        # åå‘ä¼ æ’­è·å–æ¢¯åº¦
        loss.backward()
        
        # æ·»åŠ å¯¹æŠ—æ€§æ‰°åŠ¨
        gradient = inputs.grad.data
        gradient_norms = torch.sqrt(torch.sum(gradient ** 2, dim=(1, 2, 3), keepdim=True))
        gradient = gradient / (gradient_norms + 1e-8)
        
        # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
        perturbed_inputs = inputs - self.odin_epsilon * gradient
        perturbed_inputs = torch.clamp(perturbed_inputs, 0, 1)
        
        # åœ¨æ‰°åŠ¨è¾“å…¥ä¸Šè®¡ç®—æ¸©åº¦ç¼©æ”¾çš„logits
        with torch.no_grad():
            perturbed_logits = self.model(perturbed_inputs)
            scaled_logits = perturbed_logits / self.odin_temperature
            odin_scores = F.softmax(scaled_logits, dim=1).max(dim=1)[0]
        
        return logits, odin_scores
    
    def preprocess_image(self, image_path: str) -> torch.Tensor:
        """é¢„å¤„ç†å›¾åƒ"""
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        image_tensor = self.transform(image).unsqueeze(0)
        
        return image_tensor.to(self.device)
    
    def detect_single_image(self, image_path: str) -> DetectionResult:
        """æ£€æµ‹å•å¼ å›¾åƒ"""
        start_time = time.time()
        filename = Path(image_path).name
        
        try:
            # é¢„å¤„ç†å›¾åƒ
            image_tensor = self.preprocess_image(image_path)
            
            # è®¡ç®—ODINåˆ†æ•°
            logits, odin_scores = self._odin_score(image_tensor)
            
            # è·å–é¢„æµ‹ç»“æœ
            with torch.no_grad():
                probabilities = F.softmax(logits, dim=1)
                predicted_idx = probabilities.argmax(dim=1).item()
                predicted_class = str(predicted_idx)
                predicted_class_name = self.idx_to_class.get(predicted_idx, f"Unknown_{predicted_idx}")
                confidence = probabilities.max().item()
                
                # OODæ£€æµ‹
                odin_score = odin_scores.item()
                is_ood = odin_score < self.ood_threshold
            
            processing_time = time.time() - start_time
            
            # æ„å»ºæ¦‚ç‡å­—å…¸
            prob_dict = {
                self.idx_to_class.get(i, f"class_{i}"): float(probabilities[0][i])
                for i in range(self.num_classes)
            }
            
            return DetectionResult(
                filename=filename,
                predicted_class=predicted_class,
                predicted_class_name=predicted_class_name,
                confidence=confidence,
                is_ood=is_ood,
                probabilities=prob_dict,
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"å¤„ç†å›¾åƒå¤±è´¥: {image_path}, é”™è¯¯: {e}")
            
            return DetectionResult(
                filename=filename,
                predicted_class="ERROR",
                predicted_class_name="ERROR",
                confidence=0.0,
                is_ood=True,
                probabilities={},
                processing_time=processing_time,
                error=str(e)
            )
    
    def detect_batch(self, image_paths: List[str]) -> List[DetectionResult]:
        """æ‰¹é‡æ£€æµ‹å›¾åƒ"""
        logger.info(f"å¼€å§‹æ‰¹é‡æ£€æµ‹ {len(image_paths)} å¼ å›¾åƒ")
        
        results = []
        for i, image_path in enumerate(image_paths):
            result = self.detect_single_image(image_path)
            results.append(result)
            
            if (i + 1) % 10 == 0:
                logger.info(f"å·²å¤„ç† {i + 1}/{len(image_paths)} å¼ å›¾åƒ")
        
        successful_results = [r for r in results if r.error is None]
        failed_results = [r for r in results if r.error is not None]
        
        id_samples = sum(1 for r in successful_results if not r.is_ood)
        ood_samples = sum(1 for r in successful_results if r.is_ood)
        
        logger.info(f"æ‰¹é‡æ£€æµ‹å®Œæˆï¼Œå…±å¤„ç† {len(results)} å¼ å›¾åƒ")
        logger.info(f"æˆåŠŸ: {len(successful_results)}, å¤±è´¥: {len(failed_results)}")
        logger.info(f"IDæ ·æœ¬: {id_samples}, OODæ ·æœ¬: {ood_samples}")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç®€åŒ–ç‰ˆç§å­åˆ†ç±»å’ŒOODæ£€æµ‹æ¨ç†ç®¡é“")
    parser.add_argument("--input", type=str, required=True, help="è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•")
    parser.add_argument("--output", type=str, default="models/simple_inference_results.json", help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--device", type=str, choices=["auto", "cuda", "cpu"], default="auto", help="æŒ‡å®šè®¾å¤‡")
    parser.add_argument("--threshold", type=float, default=0.2591, help="OODæ£€æµ‹é˜ˆå€¼")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨ç†ç®¡é“
    pipeline = SimpleInferencePipeline(
        device=args.device,
        ood_threshold=args.threshold
    )
    
    # å‡†å¤‡è¾“å…¥å›¾åƒåˆ—è¡¨
    input_path = Path(args.input)
    image_paths = []
    
    if input_path.is_file():
        image_paths = [str(input_path)]
    elif input_path.is_dir():
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        for ext in image_extensions:
            image_paths.extend(input_path.glob(f"**/*{ext}"))
            image_paths.extend(input_path.glob(f"**/*{ext.upper()}"))
        image_paths = [str(p) for p in image_paths]
    else:
        logger.error(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        return
    
    if not image_paths:
        logger.error("æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    logger.info(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
    
    # æ‰¹é‡æ£€æµ‹
    results = pipeline.detect_batch(image_paths)
    
    # ä¿å­˜ç»“æœ
    output_data = {
        'total_images': len(image_paths),
        'successful_images': len([r for r in results if r.error is None]),
        'failed_images': len([r for r in results if r.error is not None]),
        'results': [result.to_dict() for result in results]
    }
    
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    
    # æ‰“å°æ‘˜è¦
    successful_results = [r for r in results if r.error is None]
    id_samples = sum(1 for r in successful_results if not r.is_ood)
    ood_samples = sum(1 for r in successful_results if r.is_ood)
    
    print(f"\nğŸ” æ£€æµ‹ç»“æœæ‘˜è¦:")
    print(f"  æ€»å›¾åƒæ•°: {len(image_paths)}")
    print(f"  æˆåŠŸå¤„ç†: {len(successful_results)}")
    print(f"  IDæ ·æœ¬: {id_samples}")
    print(f"  OODæ ·æœ¬: {ood_samples}")

if __name__ == "__main__":
    main() 