#!/usr/bin/env python3
"""
ç”Ÿäº§å°±ç»ªçš„ç§å­OODæ£€æµ‹å™¨
ä½¿ç”¨ä¼˜åŒ–åçš„ODINæ–¹æ³•ï¼Œæä¾›å®Œæ•´çš„ç§å­åˆ†ç±»å’Œå¼‚å¸¸æ£€æµ‹åŠŸèƒ½
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import json
from pathlib import Path
import cv2
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass
import time

# OpenOOD imports
from openood.networks import ResNet18_224x224

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DetectionResult:
    """æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    filename: str
    predicted_class: str
    confidence: float
    is_ood: bool
    probabilities: Dict[str, float]
    processing_time: float
    method: str = "ODIN"

class SeedOODClassifier(torch.nn.Module):
    """ç§å­OODåˆ†ç±»å™¨"""
    
    def __init__(self, num_classes=10):
        super().__init__()
        self.backbone = ResNet18_224x224(num_classes=num_classes)
        self.num_classes = num_classes
        
    def forward(self, x):
        return self.backbone(x)
    
    def get_features(self, x):
        """è·å–ç‰¹å¾è¡¨ç¤º"""
        # è·å–å€’æ•°ç¬¬äºŒå±‚çš„ç‰¹å¾
        x = self.backbone.conv1(x)
        x = self.backbone.bn1(x)
        x = self.backbone.relu(x)
        x = self.backbone.maxpool(x)
        
        x = self.backbone.layer1(x)
        x = self.backbone.layer2(x)
        x = self.backbone.layer3(x)
        x = self.backbone.layer4(x)
        
        x = self.backbone.avgpool(x)
        features = torch.flatten(x, 1)
        return features

class ProductionOODDetector:
    """ç”Ÿäº§ç¯å¢ƒOODæ£€æµ‹å™¨"""
    
    def __init__(self, 
                 model_path: str = "models/best_seed_ood_classifier.pth",
                 eval_results_path: str = "models/ood_evaluation_results.json",
                 device: str = "auto"):
        """
        åˆå§‹åŒ–OODæ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            eval_results_path: è¯„ä¼°ç»“æœæ–‡ä»¶è·¯å¾„
            device: è®¾å¤‡ç±»å‹ ("auto", "cuda", "cpu")
        """
        
        # è®¾å¤‡è®¾ç½®
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½è¯„ä¼°ç»“æœ
        self._load_eval_results(eval_results_path)
        
        # åŠ è½½æ¨¡å‹
        self._load_model(model_path)
        
        # è®¾ç½®æ•°æ®å˜æ¢
        self._setup_transforms()
        
        # ODINå‚æ•° (åŸºäºæ”¹è¿›å®éªŒçš„æœ€ä¼˜å‚æ•°)
        self.odin_temperature = 1000.0
        self.odin_epsilon = 0.0014
        self.ood_threshold = 0.2591  # åŸºäºæ”¹è¿›å®éªŒçš„æœ€ä¼˜é˜ˆå€¼
        
        logger.info("ç”Ÿäº§ç¯å¢ƒOODæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_eval_results(self, eval_results_path: str):
        """åŠ è½½è¯„ä¼°ç»“æœ"""
        with open(eval_results_path, 'r', encoding='utf-8') as f:
            eval_results = json.load(f)
        
        self.num_classes = eval_results['num_classes']
        self.class_to_idx = eval_results['class_to_idx']
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        
        logger.info(f"åŠ è½½æ¨¡å‹é…ç½®: {self.num_classes} ä¸ªç±»åˆ«")
    
    def _load_model(self, model_path: str):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        self.model = SeedOODClassifier(num_classes=self.num_classes)
        
        # åŠ è½½checkpoint
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
        else:
            self.model.load_state_dict(checkpoint)
        
        self.model.to(self.device)
        self.model.eval()
        
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ: {model_path}")
    
    def _setup_transforms(self):
        """è®¾ç½®æ•°æ®å˜æ¢"""
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def _odin_score(self, inputs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è®¡ç®—ODINåˆ†æ•°
        
        Args:
            inputs: è¾“å…¥å›¾åƒå¼ é‡
            
        Returns:
            logits: æ¨¡å‹è¾“å‡º
            odin_scores: ODINåˆ†æ•°
        """
        inputs.requires_grad_(True)
        
        # å‰å‘ä¼ æ’­
        logits = self.model(inputs)
        
        # è®¡ç®—æœ€å¤§logitå¯¹åº”çš„æŸå¤±
        max_logits = logits.max(dim=1)[0]
        loss = max_logits.sum()
        
        # åå‘ä¼ æ’­è·å–æ¢¯åº¦
        loss.backward()
        
        # æ·»åŠ å¯¹æŠ—æ€§æ‰°åŠ¨
        gradient = inputs.grad.data
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ¢¯åº¦èŒƒæ•°
        gradient_norms = torch.sqrt(torch.sum(gradient ** 2, dim=(1, 2, 3), keepdim=True))
        gradient = gradient / (gradient_norms + 1e-8)
        
        # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
        perturbed_inputs = inputs - self.odin_epsilon * gradient
        perturbed_inputs = torch.clamp(perturbed_inputs, 0, 1)
        
        # åœ¨æ‰°åŠ¨è¾“å…¥ä¸Šè®¡ç®—æ¸©åº¦ç¼©æ”¾çš„logits
        with torch.no_grad():
            perturbed_logits = self.model(perturbed_inputs)
            scaled_logits = perturbed_logits / self.odin_temperature
            odin_scores = F.softmax(scaled_logits, dim=1).max(dim=1)[0]
        
        return logits, odin_scores
    
    def preprocess_image(self, image_path: str) -> torch.Tensor:
        """
        é¢„å¤„ç†å›¾åƒ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤„ç†åçš„å›¾åƒå¼ é‡
        """
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        image_tensor = self.transform(image).unsqueeze(0)
        
        return image_tensor.to(self.device)
    
    def detect_single_image(self, image_path: str) -> DetectionResult:
        """
        æ£€æµ‹å•å¼ å›¾åƒ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ£€æµ‹ç»“æœ
        """
        start_time = time.time()
        
        # é¢„å¤„ç†å›¾åƒ
        image_tensor = self.preprocess_image(image_path)
        
        # è®¡ç®—ODINåˆ†æ•° (éœ€è¦åœ¨no_gradå¤–éƒ¨è®¡ç®—)
        logits, odin_scores = self._odin_score(image_tensor)
        
        # è·å–é¢„æµ‹ç»“æœ
        with torch.no_grad():
            probabilities = F.softmax(logits, dim=1)
            predicted_idx = probabilities.argmax(dim=1).item()
            predicted_class = self.idx_to_class[predicted_idx]
            confidence = probabilities.max().item()
            
            # OODæ£€æµ‹
            odin_score = odin_scores.item()
            is_ood = odin_score < self.ood_threshold
        
        processing_time = time.time() - start_time
        
        # æ„å»ºæ¦‚ç‡å­—å…¸
        prob_dict = {
            self.idx_to_class[i]: float(probabilities[0][i])
            for i in range(self.num_classes)
        }
        
        return DetectionResult(
            filename=Path(image_path).name,
            predicted_class=predicted_class,
            confidence=confidence,
            is_ood=is_ood,
            probabilities=prob_dict,
            processing_time=processing_time
        )
    
    def detect_batch(self, image_paths: List[str]) -> List[DetectionResult]:
        """
        æ‰¹é‡æ£€æµ‹å›¾åƒ
        
        Args:
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        
        logger.info(f"å¼€å§‹æ‰¹é‡æ£€æµ‹ {len(image_paths)} å¼ å›¾åƒ")
        
        for i, image_path in enumerate(image_paths):
            try:
                result = self.detect_single_image(image_path)
                results.append(result)
                
                if (i + 1) % 10 == 0:
                    logger.info(f"å·²å¤„ç† {i + 1}/{len(image_paths)} å¼ å›¾åƒ")
                    
            except Exception as e:
                logger.error(f"å¤„ç†å›¾åƒ {image_path} æ—¶å‡ºé”™: {e}")
                # åˆ›å»ºé”™è¯¯ç»“æœ
                error_result = DetectionResult(
                    filename=Path(image_path).name,
                    predicted_class="ERROR",
                    confidence=0.0,
                    is_ood=True,
                    probabilities={},
                    processing_time=0.0
                )
                results.append(error_result)
        
        logger.info(f"æ‰¹é‡æ£€æµ‹å®Œæˆï¼Œå…±å¤„ç† {len(results)} å¼ å›¾åƒ")
        return results
    
    def save_results(self, results: List[DetectionResult], output_path: str):
        """
        ä¿å­˜æ£€æµ‹ç»“æœ
        
        Args:
            results: æ£€æµ‹ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = []
        for result in results:
            serializable_results.append({
                'filename': result.filename,
                'predicted_class': result.predicted_class,
                'confidence': result.confidence,
                'is_ood': result.is_ood,
                'probabilities': result.probabilities,
                'processing_time': result.processing_time,
                'method': result.method
            })
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_images = len(results)
        ood_count = sum(1 for r in results if r.is_ood)
        id_count = total_images - ood_count
        avg_processing_time = np.mean([r.processing_time for r in results])
        
        # æ„å»ºå®Œæ•´ç»“æœ
        full_results = {
            'summary': {
                'total_images': total_images,
                'id_samples': id_count,
                'ood_samples': ood_count,
                'ood_rate': ood_count / total_images if total_images > 0 else 0,
                'avg_processing_time': avg_processing_time,
                'method': 'ODIN',
                'threshold': self.ood_threshold
            },
            'detailed_results': serializable_results
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(full_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    def print_summary(self, results: List[DetectionResult]):
        """æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦"""
        total_images = len(results)
        ood_count = sum(1 for r in results if r.is_ood)
        id_count = total_images - ood_count
        avg_processing_time = np.mean([r.processing_time for r in results])
        
        print(f"\nğŸ” æ£€æµ‹ç»“æœæ‘˜è¦:")
        print(f"  æ€»å›¾åƒæ•°: {total_images}")
        print(f"  IDæ ·æœ¬: {id_count} ({id_count/total_images:.1%})")
        print(f"  OODæ ·æœ¬: {ood_count} ({ood_count/total_images:.1%})")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.3f}ç§’/å›¾åƒ")
        print(f"  æ£€æµ‹æ–¹æ³•: ODIN")
        print(f"  OODé˜ˆå€¼: {self.ood_threshold:.4f}")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = ProductionOODDetector()
    
    # æµ‹è¯•å›¾åƒè·¯å¾„
    test_images = []
    
    # æ·»åŠ IDæ ·æœ¬ (ä»åˆ†å‰²çš„ç§å­ä¸­é€‰æ‹©ä¸€äº›)
    segmented_dir = Path("datasets/seeds/segmented")
    if segmented_dir.exists():
        seed_images = list(segmented_dir.glob("*.jpg"))[:10]  # å–å‰10å¼ 
        test_images.extend([str(p) for p in seed_images])
    
    # æ·»åŠ OODæ ·æœ¬
    ood_dir = Path("ç«å“ç§å­")
    if ood_dir.exists():
        for category_dir in ood_dir.iterdir():
            if category_dir.is_dir():
                category_images = list(category_dir.glob("*.jpg"))[:2]  # æ¯ç±»å–2å¼ 
                test_images.extend([str(p) for p in category_images])
    
    if not test_images:
        logger.warning("æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
        return
    
    logger.info(f"æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾åƒ")
    
    # æ‰¹é‡æ£€æµ‹
    results = detector.detect_batch(test_images)
    
    # æ‰“å°æ‘˜è¦
    detector.print_summary(results)
    
    # ä¿å­˜ç»“æœ
    detector.save_results(results, "models/production_ood_results.json")
    
    # æ‰“å°ä¸€äº›è¯¦ç»†ç»“æœ
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœç¤ºä¾‹:")
    for i, result in enumerate(results[:5]):  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
        status = "ğŸš¨ OOD" if result.is_ood else "âœ… ID"
        print(f"  {i+1}. {result.filename}: {status} | "
              f"ç±»åˆ«: {result.predicted_class} | "
              f"ç½®ä¿¡åº¦: {result.confidence:.3f} | "
              f"æ—¶é—´: {result.processing_time:.3f}s")

if __name__ == "__main__":
    main() 